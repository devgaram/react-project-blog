---
layout: post-content
title: (코딩인터뷰) 시스템 설계 및 규모 확장성 문제 1 - 중복 URL
date: 2019-08-30
categories: [codinginterview]
---

코딩 인터뷰 완전분석 (CRACKING THE CODING INTERVIEW 6/E) / 게일 라크만 맥도웰 지음 / 인사이트

---

# Q. 중복 URL : 100억 개의 URL이 있다. 중복된 문서를 찾으려면 어떻게 해야 하는가? 여기서 '중복'이란 '같은 URL'이라는 뜻이다.

## 내풀이

만약 100억 개의 URL을 저장할 수 있는 충분한 공간이 있다면, 리스트를 정렬한 후 중복된 값 찾으면 될 것 같다.    
아니면 100억 개의 URL을 해시테이블에 저장하는 전처리 과정을 하면 전처리 과정 중에도 중복된 문서를 찾을 수 있고 
그 후 데이터가 추가될 때도 쉽게 중복 여부를 확인할 수 있을 것 같다.

## 책풀이

## 1단계 : 합당한 가정을 세운다.

책은 100억 개의 URL을 처리하기위한 공간을 계산하기위해 다음과 같은 합당한 가정을 세운다.

* 각 URL이 평균적으로 100개의 문자로 구성되어 있고 각 문자는 4바이트라고 가정한다.
* 100(문자) * 4(bytes) * 100억(url개수) = 4,000,000,000,000 bytes = 4 * 10<sup>12</sup> = 4TB
* 즉, 100억 개의 URL을 처리하기위해서는 4TB 정도의 메모리 공간이 필요하다.

## 2단계 : 현실적 제약을 무시한다.

모든 데이터를 메모리에 보관할 수 있다고 가정한 후 문제에 접근한다.

이미 살펴본 URL에 대해 true를 반환하는 해시테이블을 사용하여 문제를 해결할 수 있다.    
리스트를 정렬하는 방식은 시간도 더 들고 장점도 없다.

## 3단계 : 현실로 돌아온다.

4TB의 데이터를 메모리(RAM)에 전부 올릴 수 없는 상황에서 어떻게 해야하는지 생각한다.

**해법 #1 : 디스크 저장**

각 URL을 .txt 파일에 저장한다.    
.txt 파일의 크기는 1GB(10<sup>9</sup>)로 4TB URL을 저장하기위해서는 4000개의 파일이 필요하다.    
x = hash(u) % 4000로 저장할 .txt 파일을 결정한다.     
같은 해시값을 갖는 URL은 같은 파일에 저장된다.     
각 파일을 메모리에 올려 URL의 해시테이블을 생성한 다음에 중복이 존재하는 지 확인하면 된다.

**해법 #2 : 데이터를 여러 서버에 분할**

본질적으로는 해법1과 같으나, 여러 서버를 사용한다는 차이가 있다.    
URL을 .txt라는 파일에 저장하는 대신 서버 x에 전송하는 것이다.     
* 장점 : 병렬처리가능
* 단점 : 4000개의 서버가 완벽 동작해야함(비현실적)

