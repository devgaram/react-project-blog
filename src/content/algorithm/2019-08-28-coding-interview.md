---
layout: post-content
title: (코딩인터뷰) 시스템 설계 및 규모 확장성 이론
date: 2019-08-28
categories: [codinginterview]
---

(코딩인터뷰 완전분석) 책의 '시스템 설계 및 규모 확장성' 파트를 정리한 글입니다.    
이런 류의 질문에는 실제로 어떻게 행동할 것인지를 답하면 됩니다.

---

# 문제를 다루는 방법

* 면접관과 소통하기
* 처음에는 포괄적으로 접근하기
* 화이트보드에 제안하는 설계를 그리며 설명하기
* 면접관이 짚은 문제점을 인정하고 적절히 수정하기
* 가정을 할 때 주의하기
* 가정을 할 때 그것을 면접관에게 알리기
* 필요하다면 어림잡아 보기 예) 공간
* 계속해서 깊이 파고들고 질문하기

# 시스템 설계 : 단계별 접근법

면접관 : TinyUrl과 같은 시스템을 설계해보세요.    
지원자 : ???

## 1단계 : 문제의 범위를 한정하라

지원자 : 정확히 무엇을 구현해야 하는거지?..

지원자는 위와 같은 물음이 생기기 마련이다.    
질문을 통해 물음을 해결하지 않으면 지원자가 만들 시스템과 면접관이 원하는 것이 다를 수 있다.    
아래와 같은 질문을 던지면서 문제의 범위를 한정해나가는 게 필요하다.

* 개개인이 원하는 대로 축약된 URL을 만들 수 있어야 하나? 아니면 축약된 URL이 항상 자동으로 생성되는 건가?
* 클릭에 관한 통계 정보를 기록할 필요가 있나?
* 한번 설정된 URL은 영원히 없어지지 않는건가? 아니면 일정 시간이 지나면 삭제되는건가?

## 2단계 : 필요하다면 가정을 세워라, 단 합당해야 한다.

이러한 가정은 합당하지 않다.

* 시스템이 하루에 100명의 사용자를 처리할 수 있으면 된다.
* 메모리에 제약이 없다.
* URL이 제대로 동작하기까지 10분 걸린다.

이러한 가정은 합당하다.

* 하루에 최대 백만 개의 URL을 생성한다.
* 최근 데이터에 대해 최대 10분 정도 오차가 있다.


## 3단계 : 중요한 부분을 먼저 그려라

화이트보드에 시스템의 주요 부분을 다이어그램으로 그린다.

예시

* 여러 개의 프론트엔드 서버가 백엔드에서 데이터를 받아 오는 시스템
* 한 서버군은 크롤링, 다른 서버군은 크롤링 데이터를 분석하는 시스템

예를 들어 TinyURL을 설계한다면

지원자 : (사용자가 URL을 입력했을 때 어떤 식으로 진행되는 지 그린다) ...

## 4단계 : 핵심 문제점을 찾아라

* 어느 부분이 병목지점일까?
* 이 시스템이 풀어야 할 주된 문제는 무엇인가?

예를 들어 TinyURL을 설계한다면 아래와 같은 문제점을 찾아내야한다.

지원자 : 어떤 URL은 드물게 사용되는 반면 특정 URL의 사용량이 갑자기 치솟는 상황이라면..
시스템이 끊임없이 데이터베이스를 읽어오면 안될텐데....

## 5단계 : 핵심 문제점을 해결할 수 있도록 다시 설계하라

핵심 문제에 맞게 설계를 수정한다. 전체를 갈아 엎을 수도 있고 자잘한 부분만 수정해서 해결할 수도 있다.

지원자 : 캐시를 사용해서 해결하면 되려나..

# 규모 확장을 위한 알고리즘 : 단계별 접근법

면접관 : 시스템의 한 부분 혹은 알고리즘을 설계해보세요

## 1단계 : 질문하라

질문을 통해 문제를 확실히 이해해야한다.

## 2단계 : 현실적 제약을 무시하라

메모리 제약 없고, 컴퓨터 한 대에서 모든 데이터를 다 처리할 수 있다고 가정해서 풀어본다.

## 3단계 : 현실로 돌아오라

* 컴퓨터 한 대에 저장할 수 있는 데이터 크기에 대해 생각하기
* 데이터를 여러 조각으로 쪼갰을 때 어떤 문제가 발생할지 생각하기
* 데이터를 여러 조각으로 쪼갤 때 어떤 논리로 데이터를 나눌 것인지 생각하기
* 데이터를 여러 조각으로 쪼갤 때 특정 컴퓨터가 어느 데이터 조각을 사용했는지 어떻게 알 수 있을 것인지

## 4단계 : 문제를 풀어라

순환적 접근법을 이용한다.

# 시스템 설계의 핵심 개념

## 수평적 vs 수직적 규모 확장

* 수직적 규모 확장 : 특정 노드의 자원의 양을 늘리는 방법 예) 서버에 메모리 추가
* 수평적 규모 확장 : 노드의 개수를 늘리는 방법 예) 서버를 추가해서 서버 한 대가 다루는 부하를 줄인다.

## 서버 부하 분산 장치(load balancer)

일반적으로 규모 확장성이 있는 웹사이트의 프론트엔드 부분은 서버 부하 분산 장치를 통해서 제공된다.     
이렇게 해야 서버에 걸리는 부하를 여러 대의 서버에 균일하게 분신시킬 수 있고 서버 한대 때문에 전체 시스템이 죽거나
다운되는 상황을 방지할 수 있다.    
물론 서버 여러 대가 근본적으로 똑같은 코드와 데이터를 사용하도록 하는 네트워크를 구현해놔야 한다.

## 데이터베이스 역정규화(denormalization)와 NoSQL

SQL 같은 RDMS의 조인 연산은 시스템이 커질수록 굉장히 느려지므로 가능하면 피해야 한다.

역정규화란?    
데이터베이스에 여분의 정보를 추가해서 읽기 연산 속도를 향상시킨 것을 의미한다.

예를 들어, 한 프로젝트가 여러 과제를 수행하도록 설계된 데이터베이스를 생각해보자.    
이 데이터베이스에서 프로젝트 이름이랑 과제 정보를 함께 알고 싶은 경우에 두 테이블을 조인하기보단 
애초에 과제 테이블에 프로젝트 이름 정보를 추가로 저장해 놓으면 더 빠르게 작업을 수행할 수 있다.

혹은, NoSQL 데이터베이스를 이용하면 된다. 
NoSQL은 초고용량 데이터 처리 등 성능에 특화된 목적을 위해, 비관계형 데이터 저장소에, 비구조적인 데이터를 저장하기 위한 분산 저장 시스템이다.    
저장되는 데이터 구조는 주로 Key-Value 형태이다.   
예) 몽고DB    
NoSQL의 특징

- 관계형 모델을 사용하지 않으며 테이블간의 조인 기능 없음
- 직접 프로그래밍을 하는 등의 비SQL 인터페이스를 통한 데이터 액세스
- 대부분 여러 대의 데이터베이스 서버를 묶어서(클러스터링) 하나의 데이터베이스를 구성
- 관계형 데이터베이스에서는 지원하는 Data처리 완결성(Transaction ACID 지원) 미보장
- 데이터의 스키마와 속성들을 다양하게 수용 및 동적 정의 (Schema-less)
- 데이터베이스의 중단 없는 서비스와 자동 복구 기능지원
- 다수가 Open Source로 제공
- 확장성, 가용성, 높은 성능

# 데이터베이스 분할(샤딩)

샤딩(sharding)은 데이터를 여러 컴퓨터에 나눠서 저장하는 동시에 어떤 데이터가 어떤 컴퓨터에 저장되어 있는지 알 수 있는 방식을 말한다.

* 수직적 분할 : 자료의 특성별로 분할 예) SNS를 만든다면, 개인정보 부분과 메시지 부분으로 자료를 분할 (특정 테이블의 크기가 일정 수준 이상으로 커질 수 있음) 
* 키 혹은 해시 기반 분할 : mod(key, n)의 값을 이용해서 N개의 서버에 분할 (서버의 개수가 고정되어 있어야 하며, 서버를 새로 추가할 때마다 모든 데이터를 재분배 해야함)
* 디렉터리 기반 분할 : 데이터를 찾을 때 사용되는 조회 테이블(lookup table)을 유지하는 방법, 서버 추가하기는 쉬움 (조회 테이블이 *단일 장애 지점이 될 수 있음, 지속적으로 테이블 읽는 행위가 전체 성능에 영향을 미칠 수 있음)

<span class="clr-grey">*단일 장애 지점 : 네트워크의 한 지점(노드)의 장애가 전체 네트워크(시스템)의 장애를 초래하는 것</span>

## 캐싱(caching)

인메모리(in-memory) 캐시를 사용하면 결과를 빠르게 가져올 수 있다.    

* KEY-VALUE 쌍의 구조
* 애플리케이션과 데이터 저장소 사이에 자리잡고 있음
* 쿼리와 그 결과를 캐시하는 경우가 많음
* 특정 객체를 캐시에 저장할 수 있음

애플리케이션이 어떤 자료를 요청 -> 캐시를 먼저 확인 -> 캐시가 해당 키 값을 갖고 있지 않음 -> 데이터 저장소에서 자료 가져옴

예) 웹 페이지의 어떤 부분을 렌더링한 결과나 블로그에 올라온 최근 포스팅 리스트를 캐시에 갖고 있음

## 비동기식 처리 & 큐

이상적이라면, 속도가 느린 연산은 비동기식으로 처리해야 한다.    
그렇지 않으면 해당 연산이 끝나기까지 하염없이 기다려야 할 수도 있기 때문이다.    

어떤 경우에는 연산을 미리 해 큐에 넣을 수도 있다. 

예) 포럼 웹사이트에서 큐에 들어 있는 작업 중 하나는 가장 최근의 글들과 몇가지 코멘트를 보여주는 페이지를 다시 만들어 주는 일이다.    
새로운 코멘트 하나 때문에 캐시미스가 나서 웹사이트를 새로 불러오는 것보다 큐의 데이터를 이용해 약간 오래되어 덜 정확한 최신 글 리스트를 
보여주는 것이 낫다.

## 네트워크 성능 척도

* 대역폭(bandwidth) : 단위 시간에 전송할 수 있는 데이터의 최대치 (초당 몇 비트(혹은, 몇 기가 바이트)를 보낼 수 있는 가)
* 처리량(throughput) : 단위 시간에 실제로 전송된 데이터의 양
* 지연 속도(latency) : 데이터를 전송하는 데 걸리는 시간 (발송자가 데이터를 보낸 시점 - 수신자가 데이터를 받는 지점)

## MapReduce

많은 과정을 병렬로 처리할 수 있게 도와주며 굉장히 커다란 데이터를 처리하는 데 사용

* Map은 데이터를 입력으로 받은 뒤 key-value 쌍을 반환한다.
* Reduce는 키와 관련된 값들을 입력으로 받은 뒤 나름의 처리 과정을 거친 뒤 새로운 키와 값을 반환하다.

# 시스템 설계 시 고려할 점

* 실패 : 실패에 대한 대비책
* 가용성 및 신뢰성 : 가용성은 사용 가능한 시스템의 시간을 백분율로 나타낸 것, 신뢰성은 특정 단위 시간에 시스템이 사용 가능할 확률
* 읽기 중심 vs 쓰기 중심 : 쓰는 연산이 많으면 큐를 사용하는 방법이 좋음, 읽는 연산이 많으면 캐시를 사용하는 것이 좋음
* 보안

# 연습문제

수백만 개의 문서가 주어졌을 때, 특정 단어 리스트가 포함된 문서를 찾으려고 한다.    
어떻게 할 수 있을까? 단어가 등장하는 순서는 중요하지 않지만, 해당 단어가 완벽하게 나타나야 한다.

findwords를 같은 문서 집합에 대해서 여러 번 호출한다고 가정한다.

## 1단계

현실적 제약을 무시해보고 문서가 수십 개 있을 때로 가정하여 문제를 풀어본다.    
findWords를 어떻게 구현할까...?

전처리 과정을 통해 모든 문서에 대한 해시테이블을 만든다.    
해시테이블은 단어와 해당 단어를 포함하는 문서 리스트에 대한 정보를 담고 있다.

"books" -> {doc2, doc3, doc6, doc8}    
"many" -> {doc1, dod3, doc7, doc8, doc9}

"many books"를 탐색한다면, "books"와 "many"의 교집합을 구하면 된다. {doc3, doc8}

## 2단계

현실로 돌아와 문서의 개수를 수백만 개로 늘려본다.    
어떻게 해야할까?    
일단, 문서를 여러 대의 컴퓨터로 나눠서 보내야 할 것이다.    
또한 단어의 수나 출현 빈도 등 때문에 해시테이블조차도 한 컴퓨터에 온전히 보관할 수 없을 수 있다.    

실제로 해시테이블도 분할해서 저장해야 하는 상황이 벌어졌다고 가정해보자.    
그러면 다음과 같은 고민을 해야한다.    

* 해시테이블은 어떻게 분할하지? 키워드에 따라? 문서에 따라?
* 데이터를 분할하기로 결정하면, 어떤 컴퓨터에서는 문서를 처리하고 그 처리 결과를 다른 컴퓨터로 옮겨야 할텐데 어떻게 정의할 수 있을까?
* 어떤 컴퓨터에 어떤 데이터가 보관되어 있는지 알 수 있어야 할텐데.. 그리고 조회 테이블의 형태는? 조회 테이블은 어디에 두어야 되지?

## 3단계

문제점에 대한 해법을 찾아야 한다.
한 가지 방법은 키워드를 알파벳 순서에 따라 분할하는 것이다.     
즉, 한 컴퓨터가 특정한 범위의 단어들(예, after~apple)만 통제하게 하는 것이다.    
키워드를 알파벳 순서로 돌면서 가능한 데이터를 저장하는 알고리즘은 쉽게 구현할 수 있다. 용량이 꽉 차면, 다른 컴퓨터로 옮겨 가야 한다.    

장점 : 조회 테이블을 작고 단순하게 만들 수 있음, 각 컴퓨터에 조회 테이블의 복사본을 저장할 수 있음    
단점 : 새로운 문서나 단어 추가시 키워드를 굉장히 많이 이동시킴

"after builds boat amaze banana"

컴퓨터에 키워드가 알파벳 순서로 분할되어 있으니 문자열을 정렬한 후 요청을 보낸다.

일번 컴퓨터는 "after~apple" 범위의 키워드가 있으니 after와 amaze에 대한 요청을 보내고, builds, boat, banana는 삼번 컴퓨터 범위에 해당되므로
삼번 컴퓨터로 요청을 보낸다.    
각 컴퓨터에서 요청 사항에 대한 교집합을 구하여 반환한다.    
마지막으로, 초반에 전체 요청을 보낸 컴퓨터는 일번과 삼번의 컴퓨터로 부터 받은 결과의 교집합을 구하면 된다.